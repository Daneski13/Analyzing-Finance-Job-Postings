{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fecd90f-fc27-4e25-b349-c5dcf3f51436",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finance Job Market Analysis\n",
    "\n",
    "## Purpose\n",
    "\n",
    "As a finance and management information systems major I wanted to learn more about the current (2022) job market before entering within the next couple years. \n",
    "\n",
    "### Questions \n",
    "\n",
    "- **Where are the most jobs located?**\n",
    "- **Which industries have the most jobs?**\n",
    "- **How can I best prepare myself for getting a job, what skills are in demand beyond an education in Finance?**\n",
    "- **Would my MIS degree make me more marketable?**\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "For this project I developed a Python script, [linkedin-job-scraper](https://github.com/Daneski13/linkedin-job-scraper), to scrape public job listings on LinkedIn. LinkedIn is one of the most popular platforms for job seekers, making it one of the best websites to gather data on the job market.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "From September 28th through October 4th 2022, I scraped LinkedIn's job listings each day with the search keyword \"Finance\" and location of United States. Filtering for the last 24 hours, the seniority/experience levels of Internship, Entry Level, and Associate with the job types of Full Time, Internship, and Other. I was looking to collect information on Full Time jobs available to those with about 0-3 years experience in the field (\"entry jobs\") and these filters would produce the most relevant data for my questions. Queries used LinkedIn's default \"Most relevant\" sorting in an attempt to get the best data pertaining to the \"Finance\" keyword.\n",
    "\n",
    "Because LinkedIn will only display up to 1000 listings per search, I was unfortunately unable to scrape the entirety of the listings posted each day. I used separate search queries for each seniority level and further broke down those queries by filtering each for remote, hybrid, or on-site for the widest coverage. Gathering more data would not be possible without using highly specific filters introducing bias.\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "| Col             | Definition                                        |\n",
    "| --------------- | ------------------------------------------------- |\n",
    "| date_scraped    | date the listing was scraped                      |\n",
    "| title           | title of the job listing                          |\n",
    "| full_url        | LinkedIn URL of the job posting                   |\n",
    "| company         | company name                                      |\n",
    "| company_url     | company's LinkedIn URL                            |\n",
    "| location        | job's location                                    |\n",
    "| description     | raw HTML of the job's description                 |\n",
    "| seniority_level | job's seniority level                             |\n",
    "| employment_type | job's employment type (Full Time, Part Time etc.) |\n",
    "| job_function    | job's expected functions                          |\n",
    "| industries      | industries the company is in                      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0eb78226c02bc02140fdd6e51a67230ef35106452901cb0998759e99ff3e9592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
